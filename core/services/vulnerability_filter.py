# core/services/vulnerability_filter.py
"""
Vulnerability Filtering & Grouping Service - FIXED & ENHANCED
==============================================================

Responsibilities:
- Filter vulnerabilities by severity level
- Limit number of results
- Group similar vulnerabilities
- Sort by priority
"""

import logging
from typing import List, Optional, Dict, Any
from collections import defaultdict

from core.models import Vulnerability, SeverityLevel

logger = logging.getLogger(__name__)


class VulnerabilityFilter:
    """Smart filtering, grouping and sorting of vulnerabilities"""
    
    # Severity hierarchy (lower index = higher severity)
    SEVERITY_HIERARCHY = [
        SeverityLevel.CRITICAL,
        SeverityLevel.HIGH,
        SeverityLevel.MEDIUM,
        SeverityLevel.LOW,
        SeverityLevel.INFO
    ]
    
    # Severity mapping for normalization
    SEVERITY_MAP = {
        'INFO': SeverityLevel.INFO,
        'LOW': SeverityLevel.LOW,
        'MEDIUM': SeverityLevel.MEDIUM,
        'HIGH': SeverityLevel.HIGH,
        'CRITICAL': SeverityLevel.CRITICAL
    }
    
    def __init__(self):
        self.original_count = 0
        self.filtered_count = 0
        self.grouped_count = 0
        self.sorted = False
    
    def apply_filters(
        self,
        vulnerabilities: List[Vulnerability],
        min_cvss: Optional[float] = None,  # Reserved for future use
        min_severity: Optional[str] = None,
        max_vulns: Optional[int] = None,
        group_similar: bool = False,
        sort_by_priority: bool = True
    ) -> List[Vulnerability]:
        """
        Apply complete filtering pipeline
        
        Args:
            vulnerabilities: List of vulnerabilities
            min_cvss: Minimum CVSS score (reserved, not implemented yet)
            min_severity: Minimum severity level (INFO, BAJA, MEDIA, ALTA, CRÃTICA)
            max_vulns: Maximum number of vulnerabilities to return
            group_similar: Group similar vulnerabilities
            sort_by_priority: Sort by priority score
        
        Returns:
            Filtered, grouped and sorted list
        """
        # Reset stats
        self.original_count = len(vulnerabilities)
        self.grouped_count = 0
        self.sorted = False
        
        if not vulnerabilities:
            logger.info("No vulnerabilities to filter")
            self.filtered_count = 0
            return []
        
        logger.info(f"ðŸ” Filtering {len(vulnerabilities)} vulnerabilities")
        
        # Make a copy to avoid modifying original
        result = list(vulnerabilities)
        
        # Step 1: Filter by severity
        if min_severity:
            result = self._filter_by_severity(result, min_severity)
            logger.info(f"   After severity filter (>= {min_severity}): {len(result)}")
        
        # Step 2: Group similar (before sorting/limiting)
        if group_similar:
            result = self._group_similar_vulnerabilities(result)
            logger.info(f"   After grouping: {len(result)} (grouped: {self.grouped_count})")
        
        # Step 3: Sort by priority
        if sort_by_priority and result:
            result = self._sort_by_priority(result)
            self.sorted = True
            logger.info(f"   Sorted by priority: highest first")
        
        # Step 4: Limit results (after sorting to get top N)
        if max_vulns and len(result) > max_vulns:
            logger.info(f"   Limiting to top {max_vulns} vulnerabilities")
            result = result[:max_vulns]
        
        self.filtered_count = len(result)
        
        # Final summary
        removed = self.original_count - self.filtered_count
        if removed > 0:
            logger.info(
                f"âœ… Filtering complete: {self.original_count} â†’ {self.filtered_count} "
                f"({removed} removed, {self.grouped_count} grouped)"
            )
        else:
            logger.info(f"âœ… No filtering applied: {self.filtered_count} vulnerabilities")
        
        return result
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # PRIVATE METHODS
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def _filter_by_severity(
        self,
        vulnerabilities: List[Vulnerability],
        min_severity: str
    ) -> List[Vulnerability]:
        """
        Filter vulnerabilities by minimum severity level
        
        Args:
            vulnerabilities: List to filter
            min_severity: Minimum severity (string)
        
        Returns:
            Filtered list
        """
        # Normalize severity string
        min_sev = self.SEVERITY_MAP.get(min_severity.upper())
        
        if not min_sev:
            logger.warning(f"âš ï¸  Unknown severity: {min_severity}, skipping filter")
            return vulnerabilities
        
        # Get index in hierarchy
        try:
            min_index = self.SEVERITY_HIERARCHY.index(min_sev)
        except ValueError:
            logger.error(f"âŒ Severity {min_sev} not in hierarchy")
            return vulnerabilities
        
        # Filter: keep vulnerabilities with severity >= min_severity
        # (lower index = higher severity)
        filtered = []
        for v in vulnerabilities:
            try:
                v_index = self.SEVERITY_HIERARCHY.index(v.severity)
                if v_index <= min_index:
                    filtered.append(v)
            except ValueError:
                # Unknown severity, keep it to be safe
                logger.warning(f"âš ï¸  Unknown severity {v.severity} for {v.id}, keeping it")
                filtered.append(v)
        
        removed = len(vulnerabilities) - len(filtered)
        if removed > 0:
            logger.debug(f"   Removed {removed} vulnerabilities below {min_severity}")
        
        return filtered
    
    def _group_similar_vulnerabilities(
        self,
        vulnerabilities: List[Vulnerability]
    ) -> List[Vulnerability]:
        """
        Group similar vulnerabilities to reduce noise
        
        Strategy:
        - Group by (type, file)
        - Within same file, group if within 20 lines
        - Keep only the first occurrence (representative)
        - Add metadata about grouping
        
        Args:
            vulnerabilities: List to group
        
        Returns:
            List with similar vulnerabilities grouped
        """
        if len(vulnerabilities) <= 1:
            return vulnerabilities
        
        # Group by (type, file)
        groups = defaultdict(list)
        
        for vuln in vulnerabilities:
            key = (vuln.type.value, vuln.file_path)
            groups[key].append(vuln)
        
        unique = []
        total_grouped = 0
        
        for key, group_vulns in groups.items():
            if len(group_vulns) == 1:
                # Single vulnerability, no grouping needed
                unique.append(group_vulns[0])
                continue
            
            # Sort by line number
            group_vulns.sort(key=lambda v: v.line_number)
            
            # Keep representative vulnerabilities (not too close)
            kept = []
            for vuln in group_vulns:
                # Check if too close to any already kept
                too_close = any(
                    abs(vuln.line_number - k.line_number) <= 20
                    for k in kept
                )
                
                if not too_close:
                    kept.append(vuln)
            
            # Calculate how many were grouped
            grouped_in_this_group = len(group_vulns) - len(kept)
            total_grouped += grouped_in_this_group
            
            # Add metadata to representative vulnerabilities
            if grouped_in_this_group > 0:
                for k in kept:
                    k.meta['grouped_count'] = len(group_vulns)
                    k.meta['represents_multiple'] = True
                    k.meta['group_key'] = f"{key[0]}_{key[1]}"
            
            unique.extend(kept)
        
        self.grouped_count = total_grouped
        
        if total_grouped > 0:
            logger.debug(f"   Grouped {total_grouped} similar vulnerabilities")
        
        return unique
    
    def _sort_by_priority(
        self,
        vulnerabilities: List[Vulnerability]
    ) -> List[Vulnerability]:
        """
        Sort vulnerabilities by priority
        
        Sorting criteria (in order):
        1. Severity (CRITICAL > HIGH > MEDIUM > LOW > INFO)
        2. Priority score (computed property)
        3. Line number (for deterministic ordering)
        
        Args:
            vulnerabilities: List to sort
        
        Returns:
            Sorted list (highest priority first)
        """
        def sort_key(v: Vulnerability):
            try:
                # Get severity index (lower = higher priority)
                severity_index = self.SEVERITY_HIERARCHY.index(v.severity)
            except ValueError:
                # Unknown severity, put at end
                severity_index = 999
            
            # Priority score (higher = more important)
            priority = v.priority_score
            
            # Line number (for deterministic ordering)
            line = v.line_number
            
            # Return tuple: (severity_index, -priority, line)
            # Negative priority to sort descending
            return (severity_index, -priority, line)
        
        try:
            sorted_vulns = sorted(vulnerabilities, key=sort_key)
            return sorted_vulns
        except Exception as e:
            logger.error(f"âŒ Sorting failed: {e}, returning unsorted")
            return vulnerabilities
    
    def get_statistics(self) -> Dict[str, Any]:
        """
        Get filtering statistics
        
        Returns:
            Dictionary with stats
        """
        removal_rate = 0.0
        if self.original_count > 0:
            removal_rate = (self.original_count - self.filtered_count) / self.original_count * 100
        
        return {
            "original_count": self.original_count,
            "filtered_count": self.filtered_count,
            "removed_count": self.original_count - self.filtered_count,
            "grouped_count": self.grouped_count,
            "removal_rate": round(removal_rate, 1),
            "sorted": self.sorted
        }
    
    def reset_statistics(self) -> None:
        """Reset internal statistics"""
        self.original_count = 0
        self.filtered_count = 0
        self.grouped_count = 0
        self.sorted = False