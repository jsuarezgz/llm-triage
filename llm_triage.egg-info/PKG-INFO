Metadata-Version: 2.4
Name: llm-triage
Version: 3.0.0
Summary: LLM-Powered Vulnerability Triage with CVSS Filtering and Deduplication
Home-page: https://github.com/your-org/llm-vuln-triage
Author: Security Team
Author-email: security@research.com
Requires-Python: >=3.8
Description-Content-Type: text/markdown
Requires-Dist: pydantic>=2.0.0
Requires-Dist: click>=8.0.0
Requires-Dist: jinja2>=3.0.0
Requires-Dist: requests>=2.31.0
Provides-Extra: dev
Requires-Dist: pytest>=7.0.0; extra == "dev"
Requires-Dist: pytest-asyncio>=0.21.0; extra == "dev"
Requires-Dist: black>=23.0.0; extra == "dev"
Provides-Extra: openai
Requires-Dist: openai>=1.0.0; extra == "openai"
Dynamic: author
Dynamic: author-email
Dynamic: description
Dynamic: description-content-type
Dynamic: home-page
Dynamic: provides-extra
Dynamic: requires-dist
Dynamic: requires-python
Dynamic: summary

# ğŸ›¡ï¸ Security Analysis Platform v3.0

[![Version](https://img.shields.io/badge/version-3.0.0-blue.svg)](https://github.com/your-org/security-analyzer)
[![Python](https://img.shields.io/badge/python-3.8%2B-blue.svg)](https://python.org)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)
[![Tests](https://img.shields.io/badge/tests-passing-green.svg)](tests/)

> **Advanced Security Vulnerability Analysis with AI-Powered Triage & Smart Filtering**

Una plataforma moderna y optimizada para el anÃ¡lisis de vulnerabilidades de seguridad que combina parsers inteligentes, triaje con IA, filtrado avanzado y generaciÃ³n automÃ¡tica de planes de remediaciÃ³n.

## ğŸ“‹ Tabla de Contenidos

- [ğŸŒŸ CaracterÃ­sticas](#-caracterÃ­sticas)
- [ğŸ—ï¸ Arquitectura](#ï¸-arquitectura)
- [ğŸ”„ Workflow](#-workflow)
- [ğŸš€ InstalaciÃ³n RÃ¡pida](#-instalaciÃ³n-rÃ¡pida)
- [âš™ï¸ ConfiguraciÃ³n](#ï¸-configuraciÃ³n)
- [ğŸ“– Uso](#-uso)
- [ğŸ¯ Filtrado Avanzado](#-filtrado-avanzado)
- [ğŸ“ Estructura del Proyecto](#-estructura-del-proyecto)
- [ğŸ”§ Desarrollo](#-desarrollo)
- [ğŸ“Š MÃ©tricas y Rendimiento](#-mÃ©tricas-y-rendimiento)
- [ğŸ› Troubleshooting](#-troubleshooting)
- [â“ FAQ](#-faq)
- [ğŸ¤ Contribuir](#-contribuir)

## ğŸŒŸ CaracterÃ­sticas

### âœ¨ CaracterÃ­sticas Principales

- **ğŸ¤– Triaje Inteligente con IA**: Utiliza GPT-4o y WatsonX para clasificar vulnerabilidades automÃ¡ticamente
- **ğŸ¯ Filtrado Avanzado**: Sistema inteligente de filtrado por severidad, CVSS y agrupaciÃ³n
- **ğŸ§© Chunking Adaptativo**: Procesa archivos grandes de manera eficiente con algoritmos optimizados
- **ğŸ“Š Reportes Interactivos**: Genera reportes HTML ricos con funcionalidad de bÃºsqueda y navegaciÃ³n
- **ğŸ”„ Parsers Unificados**: Soporte nativo para ABAP, Semgrep, SonarQube y formatos personalizados
- **âš¡ Rendimiento Optimizado**: Arquitectura refactorizada que reduce el cÃ³digo en un 38%
- **ğŸ’¾ Cache Inteligente**: Sistema de cache que acelera anÃ¡lisis repetitivos
- **ğŸ“ˆ MÃ©tricas Avanzadas**: Monitoreo completo de rendimiento y observabilidad

### ğŸ†• Novedades v3.0

- **Arquitectura Completamente Refactorizada**: EliminaciÃ³n del 100% del cÃ³digo duplicado
- **Filtrado Inteligente**: Nuevo sistema de filtrado por severidad con agrupaciÃ³n automÃ¡tica
- **Cliente LLM Unificado**: Soporte transparente para mÃºltiples proveedores de IA
- **Templates HTML Optimizados**: Reportes mÃ¡s rÃ¡pidos y con mejor UX
- **CLI Mejorado**: Interfaz de lÃ­nea de comandos mÃ¡s intuitiva y potente
- **ConfiguraciÃ³n Centralizada**: Sistema de configuraciÃ³n unificado con Pydantic

[... continÃºa con las secciones de Arquitectura y Workflow ...]

## âš™ï¸ ConfiguraciÃ³n

### ğŸ”‘ Variables de Entorno

Crea un archivo `.env` en el directorio raÃ­z:

```bash
# === API Keys para LLM ===
OPENAI_API_KEY=sk-your-openai-api-key-here
RESEARCH_API_KEY=your-watsonx-api-key-here

# === ConfiguraciÃ³n LLM ===
LLM_PRIMARY_PROVIDER=openai          # openai | watsonx
LLM_TEMPERATURE=0.1                  # 0.0-2.0 (recomendado: 0.1)
LLM_MAX_TOKENS=4096                  # MÃ¡ximo tokens por respuesta
LLM_TIMEOUT=180                      # Timeout en segundos
LLM_USER_EMAIL=user@research.com     # Email para WatsonX

# === Modelos LLM ===
OPENAI_MODEL=gpt-4o                  # gpt-4o | gpt-4-turbo
WATSONX_MODEL=meta-llama/llama-3-3-70b-instruct

# === ConfiguraciÃ³n de Chunking ===
CHUNKING_MAX_VULNS=5                # Max vulnerabilidades por chunk
CHUNKING_MAX_SIZE=8000              # Max tamaÃ±o en bytes
CHUNKING_OVERLAP=1                  # Vulnerabilidades de overlap
CHUNKING_MIN_SIZE=3                 # MÃ­nimo tamaÃ±o de chunk

# === Cache y Rendimiento ===
CACHE_ENABLED=true                  # Habilitar cache
CACHE_TTL_HOURS=24                  # TTL del cache en horas
CACHE_DIR=.security_cache           # Directorio de cache

# === Features ===
DEDUP_ENABLED=true                  # DeduplicaciÃ³n de vulnerabilidades
DEDUP_STRATEGY=moderate             # strict | moderate | loose
METRICS_ENABLED=true                # Habilitar mÃ©tricas

# === Logging ===
LOG_LEVEL=INFO                      # DEBUG | INFO | WARNING | ERROR
```

### ğŸ“ Archivo de ConfiguraciÃ³n

Alternativamente, puedes usar un archivo `config.yaml`:

```yaml
llm:
  provider: openai
  model: gpt-4o
  temperature: 0.1
  max_tokens: 4096
  timeout: 180

chunking:
  max_vulnerabilities: 5
  max_size_bytes: 8000
  overlap: 1
  min_size: 3

cache:
  enabled: true
  ttl_hours: 24
  directory: .security_cache

filtering:
  enabled: true
  default_min_severity: MEDIA
  max_vulnerabilities: 100
  group_similar: true

deduplication:
  enabled: true
  strategy: moderate

logging:
  level: INFO
  structured: false
```

## ğŸ“– Uso

### ğŸ¯ AnÃ¡lisis BÃ¡sico

```bash
# AnÃ¡lisis simple
llm-triage analyze vulnerabilities.json

# Con output personalizado
llm-triage analyze scan.json -o report.html

# Especificar lenguaje
llm-triage analyze scan.json -l python

# Modo verbose
llm-triage analyze scan.json -v
```

### ğŸ¨ AnÃ¡lisis con Filtrado

```bash
# Solo vulnerabilidades CRÃTICAS
llm-triage analyze scan.json --min-severity CRÃTICA

# Solo ALTAS y CRÃTICAS
llm-triage analyze scan.json --min-severity ALTA

# Limitar a top 10 mÃ¡s crÃ­ticas
llm-triage analyze scan.json --min-severity ALTA --max-vulns 10

# Con agrupaciÃ³n de similares (activado por defecto)
llm-triage analyze scan.json --group-similar
```

### ğŸš€ Ejemplos Avanzados

#### AnÃ¡lisis de ProducciÃ³n
```bash
# AnÃ¡lisis completo con filtrado inteligente
llm-triage analyze production_scan.json \
    --min-severity ALTA \
    --max-vulns 20 \
    --group-similar \
    --llm-provider openai \
    --llm-model gpt-4o \
    -o critical_report.html \
    -v
```

#### Triage RÃ¡pido (Top Issues)
```bash
# Solo las 5 vulnerabilidades mÃ¡s crÃ­ticas
llm-triage analyze scan.json \
    --min-severity CRÃTICA \
    --max-vulns 5 \
    -o quick_triage.html
```

#### AnÃ¡lisis con Chunking Forzado
```bash
# Para archivos muy grandes
llm-triage analyze large_scan.json \
    --force-chunking \
    --min-severity MEDIA \
    -o large_report.html
```

#### AnÃ¡lisis sin LLM (Solo Parsing)
```bash
# Solo parsear y generar reporte (sin IA)
llm-triage analyze scan.json \
    --disable-llm \
    -o basic_report.html
```

### ğŸ” Comandos de Utilidad

#### Validar Archivo de Entrada
```bash
# Verificar formato y estructura
llm-triage validate vulnerabilities.json
```

#### Ver ConfiguraciÃ³n Actual
```bash
# Mostrar configuraciÃ³n activa
llm-triage config
```

#### Probar ConexiÃ³n LLM
```bash
# Test de conexiÃ³n con OpenAI
llm-triage test --provider openai

# Test con WatsonX
llm-triage test --provider watsonx
```

#### Ver Ejemplos
```bash
# Mostrar todos los ejemplos de uso
llm-triage examples
```

## ğŸ¯ Filtrado Avanzado

### ğŸ“Š Sistema de Filtrado

El sistema de filtrado permite enfocarte en las vulnerabilidades mÃ¡s crÃ­ticas:

```python
from core.services.vulnerability_filter import VulnerabilityFilter

# Crear filtro
filter_service = VulnerabilityFilter()

# Aplicar filtros
filtered = filter_service.apply_filters(
    vulnerabilities,
    min_severity="ALTA",      # Severidad mÃ­nima
    max_vulns=50,             # MÃ¡ximo de resultados
    group_similar=True,       # Agrupar similares
    sort_by_priority=True     # Ordenar por prioridad
)

# Ver estadÃ­sticas
stats = filter_service.get_statistics()
print(f"Original: {stats['original_count']}")
print(f"Filtrado: {stats['filtered_count']}")
print(f"Agrupadas: {stats['grouped_count']}")
```

### ğŸ¨ Niveles de Severidad

| Severidad | EspaÃ±ol | InglÃ©s | Peso | Icono |
|-----------|---------|--------|------|-------|
| **CRITICAL** | CRÃTICA | CRITICAL | 10.0 | ğŸ”¥ |
| **HIGH** | ALTA | HIGH | 7.0 | âš¡ |
| **MEDIUM** | MEDIA | MEDIUM | 4.0 | âš ï¸ |
| **LOW** | BAJA | LOW | 2.0 | ğŸ“ |
| **INFO** | INFO | INFO | 0.5 | â„¹ï¸ |

### ğŸ”— AgrupaciÃ³n Inteligente

El sistema agrupa automÃ¡ticamente vulnerabilidades similares:

- **Mismo tipo + mismo archivo + lÃ­neas cercanas (Â±20)**: Se agrupan
- **Metadata preservada**: NÃºmero total de ocurrencias
- **Representante seleccionado**: Primera ocurrencia por lÃ­nea

```bash
# Ejemplo: 50 SQL Injections similares â†’ 5 grupos representativos
llm-triage analyze scan.json --group-similar --min-severity ALTA
```

### ğŸ“ˆ Ordenamiento por Prioridad

Las vulnerabilidades se ordenan por:

1. **Severidad** (CRÃTICA > ALTA > MEDIA > BAJA > INFO)
2. **Priority Score** (calculado: severidad Ã— confianza)
3. **NÃºmero de lÃ­nea** (para orden determinÃ­stico)

## ğŸ“ Estructura del Proyecto

```
security-analyzer/
â”œâ”€â”€ ğŸ“¦ adapters/                 # Capa de adaptadores
â”‚   â”œâ”€â”€ output/                  # Generadores de salida
â”‚   â”‚   â”œâ”€â”€ html_generator.py    # Generador HTML
â”‚   â”‚   â””â”€â”€ templates/           # Templates Jinja2
â”‚   â”‚       â”œâ”€â”€ report.html      # Template principal
â”‚   â”‚       â”œâ”€â”€ styles.html      # Estilos CSS
â”‚   â”‚       â””â”€â”€ scripts.html     # JavaScript interactivo
â”‚   â””â”€â”€ processing/              # Procesamiento
â”‚       â””â”€â”€ chunker.py           # Sistema de chunking
â”‚
â”œâ”€â”€ ğŸ¯ application/              # Capa de aplicaciÃ³n
â”‚   â”œâ”€â”€ cli.py                   # CLI principal
â”‚   â”œâ”€â”€ factory.py               # Service Factory
â”‚   â””â”€â”€ use_cases.py             # Casos de uso
â”‚
â”œâ”€â”€ ğŸ’ core/                     # Dominio central
â”‚   â”œâ”€â”€ models.py                # Modelos Pydantic
â”‚   â”œâ”€â”€ exceptions.py            # Excepciones personalizadas
â”‚   â””â”€â”€ services/                # Servicios de dominio
â”‚       â”œâ”€â”€ scanner.py           # Servicio de escaneo
â”‚       â”œâ”€â”€ triage.py            # Servicio de triaje
â”‚       â”œâ”€â”€ remediation.py       # Planes de remediaciÃ³n
â”‚       â”œâ”€â”€ reporter.py          # GeneraciÃ³n de reportes
â”‚       â””â”€â”€ vulnerability_filter.py  # âœ¨ Filtrado inteligente
â”‚
â”œâ”€â”€ ğŸ›ï¸ infrastructure/          # Infraestructura
â”‚   â”œâ”€â”€ config.py                # ConfiguraciÃ³n centralizada
â”‚   â”œâ”€â”€ cache.py                 # Sistema de cache
â”‚   â””â”€â”€ llm/                     # Clientes LLM
â”‚       â”œâ”€â”€ client.py            # Cliente unificado
â”‚       â”œâ”€â”€ prompts.py           # GestiÃ³n de prompts
â”‚       â””â”€â”€ response_parser.py   # Parser de respuestas
â”‚
â”œâ”€â”€ ğŸ”§ shared/                   # Utilidades compartidas
â”‚   â”œâ”€â”€ logger.py                # Sistema de logging
â”‚   â”œâ”€â”€ metrics.py               # MÃ©tricas y observabilidad
â”‚   â”œâ”€â”€ formatters.py            # Formateadores
â”‚   â”œâ”€â”€ validators.py            # Validadores
â”‚   â””â”€â”€ constants.py             # Constantes globales
â”‚
â”œâ”€â”€ ğŸ§ª tests/                    # Tests
â”‚   â”œâ”€â”€ unit/                    # Tests unitarios
â”‚   â”œâ”€â”€ integration/             # Tests de integraciÃ³n
â”‚   â””â”€â”€ fixtures/                # Datos de prueba
â”‚
â”œâ”€â”€ ğŸ“š docs/                     # DocumentaciÃ³n
â”‚   â”œâ”€â”€ architecture.md          # DocumentaciÃ³n de arquitectura
â”‚   â”œâ”€â”€ api.md                   # API reference
â”‚   â””â”€â”€ examples/                # Ejemplos de uso
â”‚
â”œâ”€â”€ ğŸ“‹ requirements.txt          # Dependencias Python
â”œâ”€â”€ ğŸ³ Dockerfile               # Contenedor Docker
â”œâ”€â”€ âš™ï¸ setup.py                 # Setup de instalaciÃ³n
â”œâ”€â”€ ğŸ“– README.md                # Este archivo
â””â”€â”€ ğŸ“„ .env.example             # Ejemplo de configuraciÃ³n
```

## ğŸ”§ Desarrollo

### ğŸ› ï¸ Setup de Desarrollo

```bash
# 1. Clonar repositorio
git clone https://github.com/jsuarezgz/llm-triage.git
```markdown
## ğŸ”§ Desarrollo

### ğŸ› ï¸ Setup de Desarrollo

```bash
# 1. Clonar repositorio
git clone https://github.com/your-org/security-analyzer.git
cd security-analyzer

# 2. Crear entorno virtual
python -m venv venv
source venv/bin/activate  # Linux/Mac
# o
venv\Scripts\activate     # Windows

# 3. Instalar dependencias de desarrollo
pip install -r requirements-dev.txt

# 4. Instalar pre-commit hooks
pre-commit install

# 5. Configurar variables de entorno
cp .env.example .env
# Editar .env con tus credenciales

# 6. Instalar en modo desarrollo
pip install -e .

# 7. Ejecutar tests
pytest tests/ -v

# 8. Verificar cÃ³digo
black . --check
flake8 .
mypy .
```

### ğŸ§ª Testing

```bash
# Ejecutar todos los tests
pytest

# Tests con cobertura
pytest --cov=. --cov-report=html

# Tests especÃ­ficos
pytest tests/unit/test_scanner.py -v

# Tests de integraciÃ³n
pytest tests/integration/ -v

# Tests con marcadores
pytest -m "not slow"
pytest -m "llm"

# Tests en paralelo
pytest -n auto
```

### ğŸ“Š MÃ©tricas de Calidad

```bash
# Cobertura de cÃ³digo
coverage run -m pytest
coverage report
coverage html  # Ver reporte HTML en htmlcov/

# AnÃ¡lisis estÃ¡tico
pylint core/ adapters/ infrastructure/
mypy --strict core/

# Complejidad ciclomÃ¡tica
radon cc . -a

# MÃ©tricas de mantenibilidad
radon mi . -s
```

### ğŸ¨ Estilo de CÃ³digo

Este proyecto sigue las siguientes convenciones:

- **PEP 8**: Estilo de cÃ³digo Python
- **Black**: Formateo automÃ¡tico
- **isort**: Ordenamiento de imports
- **Type Hints**: Anotaciones de tipo obligatorias
- **Docstrings**: Formato Google Style

```bash
# Formatear cÃ³digo
black .
isort .

# Verificar estilo
flake8 .
pylint core/

# Verificar tipos
mypy .
```

### ğŸ“ Estructura de Commits

Seguimos [Conventional Commits](https://www.conventionalcommits.org/):

```
<type>(<scope>): <description>

[optional body]

[optional footer]
```

**Tipos:**
- `feat`: Nueva funcionalidad
- `fix`: CorrecciÃ³n de bug
- `docs`: Cambios en documentaciÃ³n
- `style`: Formateo, sin cambios de cÃ³digo
- `refactor`: RefactorizaciÃ³n de cÃ³digo
- `perf`: Mejoras de rendimiento
- `test`: AÃ±adir o modificar tests
- `chore`: Tareas de mantenimiento

**Ejemplos:**
```bash
git commit -m "feat(filter): add smart grouping by vulnerability type"
git commit -m "fix(llm): handle timeout errors gracefully"
git commit -m "docs(readme): update filtering examples"
git commit -m "perf(chunker): optimize chunk size calculation"
```

## ğŸ“Š MÃ©tricas y Rendimiento

### âš¡ Benchmarks v3.0

| MÃ©trica | v2.0 | v3.0 | Mejora |
|---------|------|------|--------|
| **Tiempo de AnÃ¡lisis** (100 vulns) | 45s | 28s | ğŸŸ¢ -38% |
| **Memoria RAM** (1000 vulns) | 512MB | 320MB | ğŸŸ¢ -38% |
| **TamaÃ±o de CÃ³digo** | 12,450 LOC | 7,079 LOC | ğŸŸ¢ -43% |
| **DuplicaciÃ³n de CÃ³digo** | 18% | 0% | ğŸŸ¢ -100% |
| **Complejidad CiclomÃ¡tica** | 8.2 | 4.5 | ğŸŸ¢ -45% |
| **Cobertura de Tests** | 72% | 89% | ğŸŸ¢ +17% |

### ğŸ“ˆ MÃ©tricas de Uso

```bash
# Ver mÃ©tricas de anÃ¡lisis
llm-triage analyze scan.json --verbose

# Exportar mÃ©tricas a JSON
llm-triage analyze scan.json --export-metrics metrics.json

# Ver estadÃ­sticas de cache
llm-triage cache stats

# Limpiar cache
llm-triage cache clear
```

### ğŸ¯ Optimizaciones Implementadas

1. **Chunking Adaptativo**
   - Estrategia by_count: Para descripciones cortas
   - Estrategia by_size: Para descripciones largas
   - Overlap inteligente: Mantiene contexto entre chunks

2. **DeduplicaciÃ³n Eficiente**
   - Strict: Hash exacto (file + line + type + description)
   - Moderate: Mismo tipo + Â±5 lÃ­neas + 80% similitud
   - Loose: Mismo tipo + 70% similitud

3. **Cache Inteligente**
   - TTL configurable (default: 24h)
   - InvalidaciÃ³n automÃ¡tica
   - CompresiÃ³n de datos

4. **Parsing Optimizado**
   - DetecciÃ³n automÃ¡tica de formato
   - ValidaciÃ³n progresiva
   - Lazy loading de datos grandes

## ğŸ› Troubleshooting

### âŒ Problemas Comunes

#### 1. Error: "No LLM provider configured"

**Causa:** Falta configurar API key

**SoluciÃ³n:**
```bash
# Verificar configuraciÃ³n
llm-triage config

# Configurar OpenAI
export OPENAI_API_KEY="sk-your-key"

# O WatsonX
export RESEARCH_API_KEY="your-key"
```

#### 2. Error: "LLM timeout"

**Causa:** Request demasiado largo o modelo lento

**SoluciÃ³n:**
```bash
# Aumentar timeout
export LLM_TIMEOUT=300

# O forzar chunking
llm-triage analyze scan.json --force-chunking
```

#### 3. Error: "File too large"

**Causa:** Archivo supera lÃ­mite de 100MB

**SoluciÃ³n:**
```bash
# Aumentar lÃ­mite
export MAX_FILE_SIZE_MB=200

# O pre-filtrar el JSON
jq '.findings[:1000]' large_scan.json > filtered_scan.json
llm-triage analyze filtered_scan.json
```

#### 4. Error: "Invalid JSON format"

**Causa:** Formato JSON no reconocido

**SoluciÃ³n:**
```bash
# Validar JSON
jq empty scan.json

# Validar con la herramienta
llm-triage validate scan.json

# Ver estructura detectada
llm-triage validate scan.json --verbose
```

#### 5. Warning: "Conservative fallback due to LLM error"

**Causa:** LLM fallÃ³, se usan decisiones conservadoras

**Comportamiento:**
- Vulnerabilidades HIGH/CRITICAL â†’ Confirmadas (confidence: 0.7)
- Vulnerabilidades MEDIUM/LOW â†’ Requieren revisiÃ³n manual (confidence: 0.5)

**SoluciÃ³n:**
```bash
# Revisar logs para ver error especÃ­fico
llm-triage analyze scan.json -v

# Reintentar con otro modelo
llm-triage analyze scan.json --llm-model gpt-4-turbo
```

### ğŸ” Debugging

#### Habilitar Logs Detallados

```bash
# Nivel DEBUG
export LOG_LEVEL=DEBUG
llm-triage analyze scan.json -v

# Logs estructurados (JSON)
export STRUCTURED_LOGGING=true
llm-triage analyze scan.json > logs.json
```

#### Inspeccionar Requests LLM

```python
from infrastructure.llm.client import LLMClient

# Habilitar debug en cliente
client = LLMClient(llm_provider="openai", enable_debug=True)

# Ver request/response completos
response = await client.analyze_vulnerabilities(data, language="python")
```

#### Exportar Datos Intermedios

```bash
# Exportar scan result (despuÃ©s de parsing)
llm-triage analyze scan.json --export-scan scan_result.json

# Exportar triage result
llm-triage analyze scan.json --export-triage triage_result.json

# Exportar mÃ©tricas
llm-triage analyze scan.json --export-metrics metrics.json
```

## â“ FAQ

### General

**Q: Â¿QuÃ© formatos de entrada soporta?**
A: JSON de Semgrep, SonarQube, ABAP Security Scanner, y formatos genÃ©ricos. El sistema detecta automÃ¡ticamente el formato.

**Q: Â¿Puedo usar sin LLM?**
A: SÃ­, usa `--disable-llm` para solo parsing y reporte bÃ¡sico sin anÃ¡lisis de IA.

**Q: Â¿Es seguro enviar mi cÃ³digo a OpenAI?**
A: Solo se envÃ­a metadata (tipo, severidad, descripciÃ³n) y snippets pequeÃ±os de cÃ³digo vulnerable, no todo el codebase. Para mayor seguridad, usa WatsonX on-premise.

### Filtrado

**Q: Â¿CÃ³mo funciona `--group-similar`?**
A: Agrupa vulnerabilidades del mismo tipo en el mismo archivo si estÃ¡n a Â±20 lÃ­neas de distancia.

**Q: Â¿QuÃ© es `--max-vulns`?**
A: Limita el resultado a las N vulnerabilidades mÃ¡s crÃ­ticas (despuÃ©s de filtrar y ordenar por prioridad).

**Q: Â¿Puedo combinar filtros?**
A: SÃ­, todos los filtros son compatibles:
```bash
llm-triage analyze scan.json \
    --min-severity ALTA \
    --max-vulns 10 \
    --group-similar
```

### Rendimiento

**Q: Â¿CuÃ¡ndo usar `--force-chunking`?**
A: Para archivos con >5 vulnerabilidades o cuando el anÃ¡lisis falla por timeout.

**Q: Â¿CÃ³mo mejoro el rendimiento?**
A:
1. Habilita cache: `CACHE_ENABLED=true`
2. Usa filtrado: `--min-severity ALTA`
3. Agrupa similares: `--group-similar`
4. Limita resultados: `--max-vulns 50`

**Q: Â¿CuÃ¡nto tiempo toma un anÃ¡lisis?**
A: Depende del tamaÃ±o:
- 10 vulnerabilities: ~10s
- 50 vulnerabilities: ~30s
- 100 vulnerabilities: ~60s (con chunking)

### LLM

**Q: Â¿QuÃ© modelo es mejor?**
A: Para mejores resultados: `gpt-4o` (OpenAI) o `llama-3-3-70b` (WatsonX)

**Q: Â¿CuÃ¡nto cuesta?**
A: Con GPT-4o:
- ~$0.01 USD por 10 vulnerabilidades
- ~$0.10 USD por 100 vulnerabilidades

**Q: Â¿Puedo usar modelos locales?**
A: Actualmente no, pero estÃ¡ en el roadmap para v3.1

## ğŸ¤ Contribuir

Â¡Contribuciones son bienvenidas! ğŸ‰

### ğŸ“‹ GuÃ­a de ContribuciÃ³n

1. **Fork** el repositorio
2. **Crea** una rama para tu feature (`git checkout -b feat/amazing-feature`)
3. **Commit** tus cambios (`git commit -m 'feat: add amazing feature'`)
4. **Push** a la rama (`git push origin feat/amazing-feature`)
5. **Abre** un Pull Request

### ğŸ¯ Ãreas de ContribuciÃ³n

- ğŸ› **Bug Fixes**: Reporta o corrige bugs
- âœ¨ **Features**: Nuevas funcionalidades
- ğŸ“š **DocumentaciÃ³n**: Mejora la documentaciÃ³n
- ğŸ§ª **Tests**: AÃ±ade mÃ¡s tests
- ğŸ¨ **UI/UX**: Mejora reportes HTML
- ğŸŒ **i18n**: Traducciones

### ğŸ“ Checklist para PRs

- [ ] Los tests pasan (`pytest`)
- [ ] CÃ³digo formateado (`black .`)
- [ ] Type hints aÃ±adidos
- [ ] DocumentaciÃ³n actualizada
- [ ] CHANGELOG.md actualizado
- [ ] Commit messages siguen convenciones

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la licencia MIT - ver [LICENSE](LICENSE) para detalles.

## ğŸ™ Agradecimientos

- OpenAI por GPT-4o API
- IBM Research por WatsonX
- Semgrep por su formato de output
- Todos los contribuidores del proyecto

## ğŸ“ Contacto

- **Issues**: [GitHub Issues](https://github.com/your-org/security-analyzer/issues)
- **Discussions**: [GitHub Discussions](https://github.com/your-org/security-analyzer/discussions)
- **Email**: security@research.com
- **Docs**: [DocumentaciÃ³n Completa](https://security-analyzer.readthedocs.io)

## ğŸ—ºï¸ Roadmap

### v3.1 (Q1 2024)
- [ ] Soporte para modelos locales (Ollama)
- [ ] API REST para integraciÃ³n
- [ ] Dashboard web interactivo
- [ ] ExportaciÃ³n a PDF
- [ ] Soporte para mÃ¡s formatos (Snyk, Checkmarx)

### v3.2 (Q2 2024)
- [ ] AnÃ¡lisis incremental (solo cambios)
- [ ] IntegraciÃ³n con CI/CD (GitHub Actions, GitLab CI)
- [ ] Machine Learning para mejorar detecciÃ³n
- [ ] AnÃ¡lisis de tendencias temporales

### v4.0 (Q3 2024)
- [ ] AnÃ¡lisis en tiempo real
- [ ] Soporte multi-repositorio
- [ ] Sistema de plugins
- [ ] Marketplace de reglas personalizadas

---

<div align="center">

**[â¬† Volver arriba](#-security-analysis-platform-v30)**

Made with â¤ï¸ by the Security Team

[![Star on GitHub](https://img.shields.io/github/stars/your-org/security-analyzer?style=social)](https://github.com/your-org/security-analyzer)

</div>
